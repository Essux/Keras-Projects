# -*- coding: utf-8 -*-
"""Dog Breed Identification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W8-IN-Pn_6ElLjPCO0Nel4RHrYjOdbG7

## Download dataset from Kaggle
"""

!pip install --upgrade --force-reinstall --no-deps kaggle
!cd /content/
api_token = {"username":"essux99","key":"b223d845353727089bbbdaae72bf1e1b"}
import json
import zipfile
import os
!mkdir '/root/.kaggle'
with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)
!chmod 600 /root/.kaggle/kaggle.json
!kaggle competitions download -c dog-breed-identification -p "/content/data"
!unzip -qq data/dog-breed-identification.zip -d data

import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
import numpy as np

"""## Split dataset in Train, Dev, Test"""

import os
from glob import glob
import shutil
from math import floor

!rm -rf data/train/train data/train/test data/train/dev

labels_df = pd.read_csv('data/labels.csv').set_index('id')

root_path = 'data/train'

files = glob(root_path + "/*")

class_files = {}

# Returns a 3-tuple with train, dev and test data respectively
def train_dev_test_split(arr, train_size, dev_size):
    train_id = floor(len(arr)*train_size)
    test_id = floor(len(arr)*dev_size) + train_id
    return arr[:train_id], arr[test_id:], arr[train_id:test_id]

# Group photos by breed
for file in files:
  base_name = os.path.basename(file)
  identifier = os.path.splitext(base_name)[0]
  breed = labels_df.loc[identifier, 'breed']
  if breed not in class_files:
    class_files[breed] = []
  class_files[breed].append(file)

partition_names = ['train', 'dev', 'test']

# Split photos in new folders
for breed, files in class_files.items():
  partitions = train_dev_test_split(files, train_size=0.6, dev_size=0.2)
  for partition_name, partition_files in zip(partition_names, partitions):
    for partition_file in partition_files:
      base_name = os.path.basename(partition_file)
      new_path = os.path.join(root_path, partition_name, breed, base_name)
      new_folder = os.path.dirname(new_path)
      if not os.path.exists(new_folder):
        os.makedirs(new_folder)
      shutil.copyfile(partition_file, new_path)

labels_df.groupby('breed').size().hist(bins=20)

"""## Keras Data Generators and Data Augmentation"""

import tensorflow.keras.applications.inception_v3 as inception_v3
from tensorflow.keras.preprocessing.image import ImageDataGenerator

BATCH_SIZE = 128
TRAIN_DIR = root_path + '/train'
DEV_DIR = root_path + '/dev'
TEST_DIR = root_path + '/test'

train_datagen = ImageDataGenerator(
    preprocessing_function=inception_v3.preprocess_input,
    rotation_range = 35,
    width_shift_range=0.15,
    height_shift_range=0.15,
    brightness_range=(0.8, 1),
    shear_range=30,
    zoom_range=0.2,
    channel_shift_range=50,
    horizontal_flip=True
)
dev_datagen = ImageDataGenerator(
    preprocessing_function=inception_v3.preprocess_input
)
test_datagen = ImageDataGenerator(
    preprocessing_function=inception_v3.preprocess_input
)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True
)
    
dev_generator = dev_datagen.flow_from_directory(
    DEV_DIR,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

test_generator = test_datagen.flow_from_directory(
    TEST_DIR,
    batch_size = BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

"""## Sample of Training Data"""

classes_names = [os.path.basename(x) for x in glob(root_path + '/train/*')]
classes_names.sort()

x_batch, y_batch = next(dev_generator)


SHOW_SAMPLES = 8
plt.figure(figsize=(16, 9))
for k, (img, lbl) in enumerate(zip(x_batch[:SHOW_SAMPLES], y_batch[:SHOW_SAMPLES])):
    breed = classes_names[np.argmax(lbl)]
    plt.subplot(2, 4, k+1)
    plt.imshow((img + 1) / 2)
    plt.axis('off')
    plt.title(breed)

"""## Sample of Data Augmentation"""

x_batch, y_batch = next(train_generator)

SHOW_SAMPLES = 32
plt.figure(figsize=(16, 9))
for k, (img, lbl) in enumerate(zip(x_batch[:SHOW_SAMPLES], y_batch[:SHOW_SAMPLES])):
    plt.subplot(4, 8, k+1)
    plt.imshow((img + 1) / 2)
    plt.axis('off')

"""## Set up Model"""

from tensorflow.keras.models import Model
from tensorflow.keras.applications.inception_v3 import InceptionV3

CLASSES = 120
    
# setup model
base_model = inception_v3.InceptionV3(
    weights='imagenet',
    include_top=False
)

# Only train last block
for layer in base_model.layers:
  layer.trainable = False
  #if layer.name == "mixed9": break

x = base_model.output
x = tf.keras.layers.GlobalMaxPooling2D(name='max_pool')(x)
x = tf.keras.layers.Dropout(0.4)(x)
x = tf.keras.layers.Dense(
    CLASSES,
    activation='softmax',
    activity_regularizer=tf.keras.regularizers.l1(0.01)
)(x)
predictions = x

model = Model(inputs=base_model.input, outputs=predictions)
optimizer = tf.keras.optimizers.Adam()
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy', 'top_k_categorical_accuracy'])

tf.keras.utils.plot_model(model)

model.summary()

"""## Training"""

EPOCHS = 15

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5,
                              patience=3, min_lr=0.00001, verbose=1, min_delta=0.01)

history = model.fit(
    x=train_generator,
    epochs=EPOCHS,
    validation_data=dev_generator,
    callbacks=[reduce_lr]
)

def plot_training(history):
  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  topk = history.history['top_k_categorical_accuracy']
  val_topk = history.history['val_top_k_categorical_accuracy']
  epochs = range(len(acc))
  
  plt.figure()
  plt.plot(epochs, loss, 'b', label='train loss')
  plt.plot(epochs, val_loss, 'r', label='val loss')
  plt.title('Training and validation loss')
  plt.ylim(0, 10)
  plt.legend()
  plt.show()

  plt.plot(epochs, acc, 'b', label='train accuracy')
  plt.plot(epochs, val_acc, 'r', label='val accuracy')
  plt.title('Training and validation accuracy')
  plt.ylim(0, 1)
  plt.legend()  
  
  
  plt.figure()
  plt.plot(epochs, topk, 'b', label='train top 5')
  plt.plot(epochs, val_topk, 'r', label='val top 5')
  plt.title('Training and validation top 5 accuracy')
  plt.ylim(0, 1)
  plt.legend()
  plt.show()
  
plot_training(history)

print('{:.4f} {:.4f}'.format(history.history['accuracy'][-1], history.history['val_accuracy'][-1]))

"""### Save Model"""

!mkdir /content/model
model.save('/content/model/model.h5')

"""## Test"""

model.evaluate(test_generator)

"""## Predictions to Submit on Kaggle"""

!mkdir data/test/challenge
!mv data/test/*.jpg data/test/challenge

CHALLENGE_DIR = '/content/data/test'

challenge_datagen = ImageDataGenerator(
    preprocessing_function=inception_v3.preprocess_input
)
    
challenge_generator = dev_datagen.flow_from_directory(
    CHALLENGE_DIR,
    batch_size=512,
    class_mode=None,
    shuffle=False
)

challenge_generator.reset()
predictions = model.predict(challenge_generator, verbose=1)

"""### Check Predictions with Photos from Google"""

challenge_generator.reset()
x_batch = next(challenge_generator)

SAMPLE_ID = 11
breed = classes_names[np.argmax(predictions[SAMPLE_ID])]
img = x_batch[SAMPLE_ID]
plt.figure(figsize=(4, 4))
plt.imshow((img + 1) / 2)
plt.axis('off')
plt.title(breed)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from IPython.display import Image
Image('https://www.worldlifeexpectancy.com/images/a/d/d/b/sealyham_terrier/sealyham_terrier_1.jpg')

"""### CSV File with Model Predictions"""

challenge_ids = [os.path.basename(x)[:-4] for x in glob('data/test/challenge/*')]
challenge_ids.sort()

df_results = pd.DataFrame(predictions, columns=classes_names, index=challenge_ids)
df_results.index.names = ['id']
df_results.to_csv('submission.csv')
df_results