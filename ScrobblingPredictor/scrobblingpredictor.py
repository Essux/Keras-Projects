# -*- coding: utf-8 -*-
"""ScrobblingPredictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KF1U1KoWwMrW4g1d6-0NFh5UiF9g9OJD
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import keras

df = pd.read_csv('data.csv', parse_dates=[3])

"""## Processing data"""

df.iloc[30:40]

df_filtered = df[df.groupby(['Artist'])['Song'].transform(lambda x : x.count()>100)]

df_filtered['month'] = df_filtered.Date.dt.to_period('M').values

df_filtered.head(10)

df_months = df_filtered.groupby(['Artist', 'month']).Song.count().reset_index()
df_months.sample(5)

df_final = df_months.set_index(['month', 'Artist']).unstack(fill_value=0).asfreq('M', fill_value=0).stack().sort_index(level=1).reset_index()
df_final.loc[130:140]

df_final[df_final.Artist=='Bayside'].plot()

data = []
for artist_name, df_g in df_final.groupby('Artist'):
  data.append(df_g.Song.values)
data = np.array(data)

data.shape

# First months used for training
months_train = 48
# Months used for prediction
window_len = 12

X_train = []
y_train = []
X_test = []
y_test = []
for i in range(data.shape[0]):
  for j in range(window_len, data.shape[1]):
    x_obs = data[i][j-window_len:j]
    y_obs = data[i][j]
    if np.sum(x_obs)<=5: continue
    if j>=months_train:
      X_test.append(x_obs)
      y_test.append(y_obs)
    else:
      X_train.append(x_obs)
      y_train.append(y_obs)
      
X_train = np.array(X_train)
y_train = np.array(y_train)
X_test = np.array(X_test)
y_test = np.array(y_test)

X_train = X_train.reshape((X_train.shape[0], window_len, 1))
X_test = X_test.reshape((X_test.shape[0], window_len, 1))

X_train.shape, X_test.shape

"""## Model"""

from keras.layers import LSTM, Dense, Input, Dropout
from keras.models import Model


def create_model(input_shape):
  model_input = Input(input_shape)
  X = LSTM(16, activation='relu')(model_input)
  X = Dropout(0)(X)
  X = Dense(1)(X)
  return Model(inputs=model_input, outputs=X)

model = create_model((window_len,1))

model.summary()

from tensorflow.keras.callbacks import ReduceLROnPlateau
import keras.backend as K

def custom_loss(y_true, y_pred):
  return K.mean(K.abs((y_true - y_pred)/(y_true+1))) * 100

model.compile(loss='mae', optimizer='adam')

history = model.fit(X_train, y_train, epochs=30, batch_size=32, shuffle=True, validation_data=(X_test, y_test))

def plot_training(history, from_=0):
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  epochs = range(len(loss))
  
  plt.plot(epochs[from_:], loss[from_:], 'b', label='train loss')
  plt.plot(epochs[from_:], val_loss[from_:], 'r', label='val loss')
  plt.title('Training and validation loss')
  plt.legend()
  plt.show()
plot_training(history)

"""### Evaluation"""

class MeanModel:
  def predict(self, X):
    return np.mean(X, axis=1)
  
class LastModel:
  def predict(self, X):
    return X[:,-1]

def mean_absolute_percentage_error(y_true, y_pred):
  eps = 1
  return np.mean(np.abs((y_true - y_pred) / (y_true+eps))) * 100

df_res = pd.DataFrame(X_train.reshape(X_train.shape[0], window_len))
df_res['real'] = y_train
df_res['predicted'] = model.predict(X_train)
df_res['baseline'] = MeanModel().predict(X_train)
df_res.sample(10)

import sklearn.metrics 
print('Baseline: {:.2f}'.format(sklearn.metrics.mean_squared_error(df_res.real, df_res.baseline)))
print('Model: {:.2f}'.format(sklearn.metrics.mean_squared_error(df_res.real, df_res.predicted)))

df_res = pd.DataFrame(X_test.reshape(X_test.shape[0], window_len))
df_res['real'] = y_test
df_res['predicted'] = model.predict(X_test)
df_res['baseline'] = MeanModel().predict(X_test)
df_res.sample(10)

import sklearn.metrics 
print('Predict Zeros: {:.2f}'.format(sklearn.metrics.mean_absolute_error(df_res.real, np.zeros((len(df_res), 1)))))
print('Baseline: {:.2f}'.format(sklearn.metrics.mean_absolute_error(df_res.real, df_res.baseline)))
print('Model: {:.2f}'.format(sklearn.metrics.mean_absolute_error(df_res.real, df_res.predicted)))



data[5]

artist_id = 56
plot_real = data[artist_id][:window_len-1].tolist()
plot_pred = []
plot_base = []

for i in range(window_len, data.shape[1]):
  x_obs = data[artist_id][i-window_len:i]
  y_obs = data[artist_id][i]
  y_pred = np.squeeze(model.predict(x_obs.reshape((1, window_len, 1))))
  y_pred = max(y_pred, 0)
  y_base = np.squeeze(MeanModel().predict(x_obs.reshape((1, window_len, 1))))
  y_real = y_obs
  plot_real.append(y_real)
  plot_pred.append(y_pred)
  plot_base.append(y_base)
  #print(x_obs, y_real, y_pred)


plt.plot(range(len(plot_real)), plot_real, 'r', label='real')
plt.plot(range(window_len-1, len(plot_real)), plot_pred, 'b', label='LSTM')
plt.plot(range(window_len-1, len(plot_real)), plot_base, 'g', label='baseline model')
plt.legend()